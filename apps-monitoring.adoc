= Lab3 - Application Monitoring
:experimental:
:tip-caption: :bulb:
:imagesdir: images

前回のラボでは、Quarkus フレームワークを使った CodeReady Workspaces を使って、クラウドネイティブアプリをデバッグしてエラーを素早く修正する方法を学び、開発者の喜びのための Quarkus の力を垣間見ることができました。

クラウドネイティブ・アプリケーションが急速に開発されているため、本番環境での分散アーキテクチャは、ネットワークと観測性という2つの分野で最終的に複雑になるからです。後日、service mesh を使用してアプリケーションをより良く管理・監視する方法を探ります。

このラボでは、 https://www.jaegertracing.io/[Jaeger^] と https://prometheus.io/[Prometheus^] を使用して coolstore アプリケーションを監視します。

image::quarkus-jaeger-prometheus.png[logo, 700]

*Jaeger* は、以下のようなマイクロサービスベースの分散システムを監視し、トラブルシューティングを行うためのオープンソースの分散トレースツールです。

* 分散型トランザクションの監視 (Distributed context propagation)
* 分散型トランザクションの監視 (Distributed transaction monitoring)
* 根本原因分析 (Root cause analysis)
* サービス依存性分析 (Service dependency analysis)
* パフォーマンスとレイテンシの最適化 (Performance and latency optimization)

*Prometheus* は、オープンソースのシステム監視およびアラートツールで、以下のような任意の数値時系列の記録に適合しています。

* メトリック名とキー/値のペアによる多次元時系列データ (Multi-dimensional time series data by metric name and key/value pairs)
* 分散型ストレージに依存しない (No reliance on distributed storage)
* HTTPを利用した時系列コレクション (Time series collection over HTTP)
* 中間ゲートウェイを介して時系列をプッシュすることができます (Pushing time series is supported via an intermediary gateway)
* サービスの発見または静的な設定 (Service discovery or static configuration)

==== 1. OpenShift プロジェクトの作成

このステップでは、CoolStore アプリケーション用の新しい監視ツールを展開します。
そのため、monolith や以前に作成した他のマイクロサービスとは別のプロジェクトを作成しておきます。

{{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-coolstore-dev[Topology View^] に戻り、プロジェクトのドロップダウンをクリックして、Create Project を選択します。 

image::create_project.png[create_dialog, 700]

フィールドに以下の内容を入力し、 *Create* をクリックします。

* Name: `{{USER_ID}}-monitoring`
* Display Name: `{{USER_ID}} CoolStore App Monitoring Tools`
* Description: 空欄にする

image::create_monitoring_dialog.png[create_dialog, 700]

==== 2. OpenShift へ Jaeger を デプロイする

Jaeger をデプロイするには、ページ上の `YAML` コンポーネントをクリックします。

image::yaml-editor.png[serverless, 800]

以下の _Service_ を `YAML` エディタでコピーし、 *Create* をクリックします。

[source,yaml,role="copypaste"]
----
apiVersion: jaegertracing.io/v1
kind: Jaeger
metadata:
  name: jaeger-all-in-one-inmemory
  namespace: {{ USER_ID }}-monitoring
----

{{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-monitoring[Topology View^] 
では、Jaegerがデプロイされているのが確認できます。

image::jaeger_top.png[create_dialog, 500]

==== 3. Jaeger UI を確認する

デプロイが完了したら（紺色の丸印！）、 https://jaeger-all-in-one-inmemory-{{USER_ID}}-monitoring.{{ ROUTE_SUBDOMAIN}}[Jaeger UI^] を開きます。

これは Jaeger の UI です。今のところ監視しているアプリがないので割と使い勝手が悪いように見えますが、心配しないしてください！
次のステップではトレースデータを活用していきます。

image::jaeger-ui.png[jaeger_ui, 700]

==== 4. Inventory で Opentracing を活用する (Quarkus)

クラウドネイティブアプリケーションの一部として Quarkus で書かれたインベントリサービスを呼び出す、 Spring Boot で書かれたカタログサービスがあります。これらのアプリケーションは、 Jaeger を使って簡単にトレースすることができます。

このステップでは、 *smallrye-opentracing* を使用するためのインベントリアプリケーションに Quarkus の拡張機能を追加します。以下のコマンドを実行して、 CodeReady Workspaces Terminal 経由でトレース拡張機能を追加します。

[source,sh,role="copypaste"]
----
mvn -q quarkus:add-extension -Dextensions="smallrye-opentracing" -f $CHE_PROJECTS_ROOT/cloud-native-workshop-v2m2-labs/inventory
----

下記を見てください。

[source,console]
----
✅ Extension io.quarkus:quarkus-smallrye-opentracing has been installed
----

これにより、インベントリマイクロサービスのために拡張機能の依存関係が `pom.xml` に追加されることが保証されます。

[NOTE]
====
https://vertx.io/[Vert.x^] 、 http://camel.apache.org/[Apache Camel^] 、 http://infinispan.org/[Infinispan^] 、Spring DI互換性（ `@Autowired` など）など、人気のあるフレームワークの Quarkusの https://quarkus.io/extensions/[拡張機能^] は他にもたくさんあります。
====

==== 5. Jeager の Configuration の作成

このステップを始める前に、 {{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-monitoring[Topology View^] にアクセスして *jaeger-collector* サービスを確認し、_jaeger_ デプロイメントをクリックして _Resources_ タブを選択して、 Jaeger によって公開されているサービスを表示します。

image::jaeger-services.png[create_dialog, 700]

ポート `14268` で `http-c-binary-trft` サービスを使用してトレースを報告するようにアプリを設定します。

workspace `cloud-native-workshop-v2m2-lab` の下にある `inventory` プロジェクトで、 `src/main/resources/application.properties` ファイルを開き、 CodeReady Workspaces Terminal を通じて以下の設定を追加します。

[source,properties,role="copypaste"]
----
# Jaeger configuration
%prod.quarkus.jaeger.service-name=inventory
%prod.quarkus.jaeger.sampler-type=const
%prod.quarkus.jaeger.sampler-param=1
%prod.quarkus.jaeger.endpoint=http://jaeger-all-in-one-inmemory-collector.{{ USER_ID }}-monitoring.svc.cluster.local:14268/api/traces
----

環境変数やJVMのプロパティを使って設定を指定することもできます。 https://www.jaegertracing.io/docs/1.12/client-features/[Jaeger Features^] を参照してください。

[NOTE]
====
もし `quarkus.jaeger.service-name` プロパティ (または環境変数 `JAEGER_SERVICE_NAME`) が指定されていない場合は、`no-op` トレーサーが設定され、バックエンドにトレースデータが報告されません。
====

[NOTE]
====
アプリケーションには特定のトレースコードは含まれていません。デフォルトでは、アプリに送信された RESTful リクエストは、MicroProfile Tracing のおかげで *コードの変更を必要とせず* にトレースされます。また、トレース情報を強化し、他のメソッドやクラスを手動でトレースすることも可能です。これについての詳細は、 https://github.com/eclipse/microprofile-opentracing/blob/master/spec/src/main/asciidoc/microprofile-opentracing.asciidoc[MicroProfile OpenTracing specification^] 仕様を参照してください。
====

==== 6. OpenShift への再デプロイ

ターミナルを介してインベントリアプリケーションをリパッケージし、再デプロイします。

[source,sh,role="copypaste"]
----
oc project {{ USER_ID }}-inventory && \
mvn package -DskipTests -f $CHE_PROJECTS_ROOT/cloud-native-workshop-v2m2-labs/inventory
----

コンソールと {{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-inventory[Inventory Topology View^] で、再構築と再展開が完了するのを待ちます。

==== 7. Jaeger トレースの観測

ネットワークとデータトランザクションをトレースするために、 CodeReady Workspaces Terminal を介して *curl* コマンドを使用してInventoryサービスを呼び出します。

トレースを生成するには、インベントリを10回呼び出します。

[source,sh,role="copypaste"]
----
URL="http://$(oc get route -n {{ USER_ID }}-inventory inventory -o jsonpath={% raw %}"{.spec.host}"{% endraw %})"

for i in $(seq 1 10) ; do
  curl -s $URL/services/inventory/165613
  sleep 2
done
----

https://jaeger-all-in-one-inmemory-{{USER_ID}}-monitoring.{{ ROUTE_SUBDOMAIN}}[Jaeger UI^] をリロードすると、新しい `inventory` サービスが Jaeger 自身のサービスと並んで表示されることに気づくでしょう。

image::jaeger-2-services.png[jaeger_ui, 700]

`inventory` サービスを選択し、 *Find Traces* をクリックして、グラフ上の最初のトレースを観察します。

image::jaeger-reload.png[jaeger_ui, 700]

単一の *Span* をクリックすると、操作名、操作の開始時刻、期間を持つ論理的な作業単位が Jaeger に表示されます。 Span は、因果関係をモデル化するために入れ子にしたり、順序をつけたりすることができます。

image::jaeger-span.png[jaeger_ui, 700]

アプリケーションがより複雑になり、多くのマイクロサービスが互いに呼び合うようになると、これらの Span やトレースはより複雑になりますが、アプリの問題点も明らかになります。

==== 8. Prometheus を OpenShift へデプロイする

OpenShift Container Platformは、 https://prometheus.io[Prometheus] オープンソースプロジェクトとその広範なエコシステムをベースにした、構成済みで自己更新型の監視スタックを搭載して提供されます。クラスタコンポーネントの監視を提供し、発生した問題をクラスタ管理者に即座に通知する一連のアラートと一連の https://grafana.com/[Grafana] ダッシュボードを搭載しています。

image::monitoring-diagram.png[Prometheus, 700]

ただし、インベントリとカタログアプリケーションのサービスメトリクスをスクレイプするために、カスタムの *Prometheus* をデプロイします。そして、そのメトリクスデータを *Grafana* ダッシュボードを使って可視化していきます。

{{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-monitoring[Monitoring Topology View^] で、 `+Add` をクリックし、 *Container Image* を選択します。

image::add-to-project.png[Prometheus, 800]

以下の項目を記入してください。

* *Image Name*: `quay.io/prometheus/prometheus`
* *Application Name*: `prometheus-app`
* *Name*: `prometheus`

*Enter* を押すと、30秒後に *緑色のチェック付き* アイコンと *Validated* が表示されます。

残りはそのままにして、 *Create* をクリックします。

image::search-prometheus-image.png[Prometheus, 700]

Topology view では、 prometheus がデプロイされているのがわかります。
それが完了したら、矢印をクリックして prometheus query UI にアクセスします。

image::prometheus-route.png[Prometheus, 700]

これは Prometheus Web UI をロードするはずです（これは後で使います）。

image::prometheus-webui.png[Prometheus, 700]

==== 9. Grafana を OpenShift へデプロイする

先ほどと同じ手順で行います。 {{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-monitoring[Monitoring Topology View^] で、 `+Add` をクリックして、 *Container Image* ,を選択し、フィールドに記入します。

* *Image Name*: `registry.redhat.io/openshift4/ose-grafana`
* *Application*: `grafana-app`
* *Name*: `grafana`

image名の横にある "虫眼鏡" の検索アイコンをクリックして、image が存在することを確認してください。

*Enter* を押すと、30秒後に *緑色のチェック付き* アイコンと *Validated* が表示されます。

残りはそのままにして、 *Create* をクリックします。

image::search-grafana-image.png[Grafana, 700]

Topology view では、 Grafana がデプロイされているのがわかります。
それが完了したら、矢印をクリックして Grafana UI にアクセスします。

image::grafana-route.png[Prometheus, 700]

これは Grafana Web UI をロードする必要があります。

image::grafana-login.png[Grafana, 700]

以下の値を使用して Grafana Web UI にログインします。

* Username: `admin`
* Password: `admin`

新しいパスワードを *スキップ* して下さい。(または覚えている他のものに変更)

このように Grafana のランディングページが表示されます。

image::grafana-webui.png[Grafana, 700]

==== 10. Grafana へデータソースを追加する

Add data source をクリックし、データソースのタイプとして *Prometheus* を選択します。

image::grafana-datasource-types.png[Grafana, 700]

以下の値を記入してください。

* *URL*: `http://prometheus.{{USER_ID}}-monitoring:9090`

*Save & Test* をクリックして、成功のメッセージが表示されたことを確認します。

image::grafana-ds-success.png[Grafana, 300]

この時点で、 Granana は、監視しているアプリケーションから収集したメトリクスを Prometheus から引き出すように設定されています。

==== 11. Inventory Microservice のメトリクスの活用

このステップでは、_Inventory(Quarkus)_アプリケーションが、Micrometer Registry Prometheus extension を通じてhttps://quarkus.io/guides/micrometer[Micrometer Metrics^]仕様を利用する方法を学びます。
 _MicroProfile Metrics_ を使用すると、アプリケーション内で何が起こっているかについての洞察を提供する様々なメトリクスや統計情報を収集することができます。

https://micrometer.io/[Micrometer^] では、アプリケーションが様々なメトリクスや統計情報を収集し、アプリケーション内部で起こっていることを把握することができます。
これらは、問題をピンポイントで特定し、キャパシティプランニングのための長期的なトレンドデータを提供し、問題を積極的に発見するのに役立ちます
（例：ディスク使用量が際限なく増加している場合）。
メトリクスは、スケジューリングシステムが、アプリケーションをより多くのマシンまたはより少ないマシンで実行するために、
いつスケールアップするかを決定するのにも役立ちます。

Micrometerは、異なるモニタリングシステムをサポートするコアライブラリと追加ライブラリのセットを定義しています。
Quarkus Micrometer の拡張機能も同様に構成されています。
_quarkus-micrometer_ は、micrometer のコアサポートとランタイムの統合を提供し、その他のサポートする Quarkus および _Quarkiverse_ の拡張機能は、
特定の監視システムをサポートするための追加の依存関係と要件をもたらします。

必要な Quarkus の _micrometer-registry-prometheus_ extensions を、CodeReady のターミナルで以下のコマンドを使用して Inventory アプリケーションに追加します。

[source,sh,role="copypaste"]
----
mvn -q quarkus:add-extension -Dextensions="micrometer-registry-prometheus" -f $CHE_PROJECTS_ROOT/cloud-native-workshop-v2m2-labs/inventory
----

出力を確認してみてください。

[source,console]
----
✅ Extension io.quarkus:quarkus-micrometer-registry-prometheus has been installed
----

目的のメトリクスが時間の経過とともに計算され、 _Prometheus_ や _Grafana_ で処理するためにエクスポートできるように、いくつかのアノテーションを追加してみましょう。

集めようとしているメトリクスは、以下のようなものです。

* *performedChecksAll*: _getAll()_ が何回実行されたかを表すカウンタ。
* *checksTimerAll*: _getAll()_ メソッドを実行するのにかかる時間の目安。
* *performedChecksAvail*: _getAvailability()_ が何回呼ばれたかを表すカウンタ
* *checksTimerAvail*: _getAvailability()_ メソッドを実行するのにかかる時間の目安。

_cloud-native-workshop-v2m2-labs/inventory_ プロジェクトで、 `src/main/java/com/redhat/coolstore/InventoryResource.java` を開きます。

インベントリを取得した回数をカウントするメトリックを追加してみましょう。以下の `MeterRegistry` 仕様を追加します:

[source,java,role="copypaste"]
----
    private final MeterRegistry registry;
    InventoryResource(MeterRegistry registry) {
        this.registry = registry;
    }
----

_getAll()_ と _getAvailability()_ の2つのメソッドを以下のコードに置き換えて、*counter* と *timer* のAPIを追加します:

[source,java,role="copypaste"]
----
    @GET
    public List<Inventory> getAll() {
        registry.counter("inventory.performedChecksAll.counter").increment();
        registry.timer("inventory.performedChecksAll.timer").record(3000, TimeUnit.MILLISECONDS);
        return Inventory.listAll();
    }

    @GET
    @Path("{itemId}")
    public List<Inventory> getAvailability(@PathParam String itemId) {
        registry.counter("inventory.performedChecksAvail.counter").increment();
        registry.timer("inventory.checksTimerAvail.timer").record(3000, TimeUnit.MILLISECONDS);
        return Inventory.<Inventory>streamAll()
        .filter(p -> p.itemId.equals(itemId))
        .collect(Collectors.toList());
    }
----

上部に必要なインポートを追加します。

[source,java,role="copypaste"]
----
import java.util.concurrent.TimeUnit;
import io.micrometer.core.instrument.MeterRegistry;
----

==== 12. OpenShift へ再デプロイ

インベントリアプリケーションをリパッケージして再配置します。

[source,sh,role="copypaste"]
----
oc project {{ USER_ID }}-inventory && \
mvn clean package -DskipTests -f $CHE_PROJECTS_ROOT/cloud-native-workshop-v2m2-labs/inventory
----

`BUILD SUCCESS` を取得して、アプリが再デプロイされるはずです。
アプリが再デプロイされるまで {{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-inventory[Inventory Topology View^] を監視してください。

これが完了すると、ターミナルでこのコマンドを使用して、アプリによって公開されている生のメトリクスを見ることができるはずです。

[source,sh,role="copypaste"]
----
curl http://inventory-{{USER_ID}}-inventory.{{ ROUTE_SUBDOMAIN }}/q/metrics
----

OpenMetrics形式のメトリクスの束が表示されます。

[source,console]
----
# TYPE http_server_bytes_read summary
http_server_bytes_read_count 1.0
http_server_bytes_read_sum 0.0
# HELP http_server_bytes_read_max
# TYPE http_server_bytes_read_max gauge
http_server_bytes_read_max 0.0
... and more
----

これは、クラスタにデプロイしたときに、プロメテウスがアプリのメトリクスにアクセスしてインデックスを作成するために使用するものです。しかし、最初に Prometheus にこのことを伝えなければなりません。

==== Prometheus ConfigMap の構成

Prometheus にアプリからメトリクスを取得するように指示するには、Kubernetes _ConfigMap_ を作成する必要があります。

{{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-monitoring[Monitoring Topology View^] 上で、左の `+Add` をクリックし、今回は *YAML* を選択します。

image::add-yaml.png[prometheus, 700]

空のボックスに、以下のYAMLコードを貼り付けます。

[source,yaml,role="copypaste"]
----
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: {{USER_ID}}-monitoring
data:
  prometheus.yml: >-
    scrape_configs:
      - job_name: 'prometheus'
        static_configs:
        - targets: ['localhost:9090']

      - job_name: 'inventory-quarkus'
        metrics_path: '/q/metrics'
        static_configs:
        - targets: ['inventory.{{USER_ID}}-inventory.svc.cluster.local:8080']
----

*Create* をクリックして下さい。

Config maps はキーと値のペアを保持しており、上記のコマンドでは *prometheus-config* という Config maps が *prometheus.yml* をキー、上記の内容を値として作成されています。コンフィグマップがコンテナに注入されるたびに、ファイルシステム上の指定されたパスに、キーと同じ名前のファイルとして表示されます。

次に、Prometheus コンテナが読めるように、この Config Map をファイルシステムに _マウント_ する必要があります。このコマンドを実行して、Prometheus デプロイメントをマウントするように変更します。

[source,sh,role="copypaste"]
----
oc set volume -n {{USER_ID}}-monitoring deployment/prometheus --add -t configmap --configmap-name=prometheus-config -m /etc/prometheus/prometheus.yml --sub-path=prometheus.yml && \
oc rollout status -n {{USER_ID}}-monitoring -w deployment/prometheus
----

これは prometheus の新しいデプロイメントを指示します。完了までお待ちください!

==== 13. メトリクスの値を生成する

Prometheus がアプリから値を取得しているので、インベントリサービスを複数回呼び出すループを書いて、メトリクスを観察してみましょう。次のコマンドを使用します。

[source,sh,role="copypaste"]
----
URL=http://$(oc get route -n {{ USER_ID }}-inventory inventory -o jsonpath={% raw %}"{.spec.host}"{% endraw %})

for i in $(seq 1 600) ; do
  curl -s $URL/services/inventory/165613
  curl -s $URL/services/inventory
  sleep 1
done
----
このループを実行したままにしておきます（600秒後、または10分後に終了します）。

メトリクスを見る方法は3つあります。

. `curl` commands (which you already did)
. Prometheus Queries
. Grafana Dashboards

==== 14. Prometheus を使ってみる

http://prometheus-{{USER_ID}}-monitoring.{{ ROUTE_SUBDOMAIN }}[Prometheus UI^] を開き、 `performedChecks` と入力して自動補完の値を選択します。

image::prometheus-metrics-console.png[metrics_prometheus, 900]

*Graph* タブに切り替えます。

image::prometheus-metrics-graph.png[metrics_prometheus, 900]

このメトリックのために、時間の値で遊んだり、異なる時間範囲で異なるデータを見たりすることができます。
他にも多くのメトリクスがあり、 https://prometheus.io/docs/prometheus/latest/querying/basics/[Prom QL^] (Prometheus Query Language) を使用してクエリを実行したり、非常に複雑なクエリを実行したりすることができます。

==== 15. Grafana を使ってみる

http://grafana-{{USER_ID}}-monitoring.{{ ROUTE_SUBDOMAIN }}[Grafana UI^] を開きます。

*New Dashboard* を選択して、メトリクスを確認するための新しい _Dashboard_ を作成します。

image::grafana-create-dashboard.png[metrics_grafana, 900]

*Add new panel* をクリックすると、クエリで新しいパネルが追加されます。

image::grafana-add-query.png[metrics_grafana, 700]

_Metrics_ フィールドに `performedChecks` と入力し、最初に自動補完された値を選択します。

image::grafana-add-query-detail.png[metrics_grafana, 700]

カーソルがフィールドに入っている間に kbd:[ENTER] を押すと、値が表示されます。表示されているようにドロップダウンから *Last 15 Minutes* を選択します。

image::grafana-add-query-detail2.png[metrics_grafana, 700]

グラフの種類（棒グラフ、線グラフ、ゲージなど）とともに、表示を微調整することができます。終わったら、*Save* ボタンをクリックして、新しいダッシュボードに名前を付けて、*Save* をクリックします。

image::grafana-add-query-detail3.png[metrics_grafana, 700]

これはオプションですが、必要に応じて Panel を追加することもできます。JVM RSSの値 `process_resident_memory_bytes` (Visualizationの `Gauge` と _Field_ タブの単位を `bytes(IEC)` に、 _Panel Title_ のタイトルを `Memory` に設定します)。こんな感じになるかもしれません。

image::grafana-add-query-detail4.png[metrics_grafana, 700]

https://grafana.com/grafana/dashboards[Grafana Labs Dashboard community^] から、より複雑なダッシュボードの例を見ることができ、さらには自分のダッシュボードにインポートすることもできます。

=== 参考情報: Spring Boot

Spring Boot は Prometheus が収集したメトリクスを公開し、Grafana で表示することもできます。Spring Boot で書かれたカタログサービスにメトリクスのサポートを追加するには、以下のようにする必要があります。

. Spring Boot Actuator と Prometheus の依存関係を追加します
.  `application-openshift.properties` を config 値で設定します。
. 以前のモジュールのコマンドを使用して、アプリを再構築し、OpenShiftに再デプロイします。（ {{USER_ID}}-catalog project 内）
. Prometheus _ConfigMap_ を編集して、 `catalog-springboot.{{USER_ID}}-catalog.svc.cluster.local:8080` を指す別のスクレイプジョブを追加します。
. Prometheus を再デプロイして新しい config を取得します。
. Prometheus に Spring Boot のメトリクス(scrape_duration_secondsなど)を問い合わせてみます。

このラボではご紹介のみになりますが、もし興味のある方、時間に余裕のある方は、是非やってみてください。

[TIP]
====
以下のコードを、pom.xml に追加します:
[source,properties,role="copypaste"]
----
<dependency>
	<groupId>io.micrometer</groupId>
	<artifactId>micrometer-registry-prometheus</artifactId>
</dependency>
----

アクチュエータを設定するには、以下のプロパティを設定する必要があります:
[source,properties,role="copypaste"]
----
management.metrics.export.prometheus.enabled=true
management.endpoints.web.exposure.include=info,health,metrics,prometheus
----

これにより、/actuator/prometheusにprometheus 形式のメトリクスが公開されます。
以下のprometheusの設定により、これらのメトリクスをスクレイピングすることができます。
[source,yaml,role="copypaste"]
----
    - job_name: 'catalog-springboot'
      metrics_path: '/actuator/prometheus'
      scrape_interval: 10s
      scrape_timeout: 5s
      static_configs:
      - targets: ['catalog-springboot.{{ USER_ID }}-catalog.svc.cluster.local:8080']
----
====

=== Summary

このラボでは、 Jaeger、Prometheus、Grafana を使用してクラウドネイティブアプリケーションを監視する方法を学びました。
また、 Quarkus を使用することで、開発者やオペレータとしての観察タスクが容易になることも学びました。
これらのテクニックを将来のプロジェクトで使用して、分散型クラウドネイティブアプリケーションを監視することができます。
