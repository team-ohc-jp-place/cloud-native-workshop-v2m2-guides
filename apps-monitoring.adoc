= Lab3 - Application Monitoring 
:experimental:

前回のラボでは、Quarkus フレームワークを使った CodeReady Workspaces を使って、クラウドネイティブアプリをデバッグしてエラーを素早く修正する方法を学び、開発者の喜びのための Quarkus の力を垣間見ることができました。

クラウドネイティブ・アプリケーションが急速に開発されているため、本番環境での分散アーキテクチャは、ネットワークと観測性という2つの分野で最終的に複雑になるからです。後日、service mesh を使用してアプリケーションをより良く管理・監視する方法を探ります。

このラボでは、 https://www.jaegertracing.io/[Jaeger^] と https://prometheus.io/[Prometheus^] を使用して coolstore アプリケーションを監視します。

image::quarkus-jaeger-prometheus.png[logo, 700]

*Jaeger* は、以下のようなマイクロサービスベースの分散システムを監視し、トラブルシューティングを行うためのオープンソースの分散トレースツールです。

* 分散型トランザクションの監視 (Distributed context propagation)
* 分散型トランザクションの監視 (Distributed transaction monitoring)
* 根本原因分析 (Root cause analysis)
* サービス依存性分析 (Service dependency analysis)
* パフォーマンスとレイテンシの最適化 (Performance and latency optimization)

*Prometheus* は、オープンソースのシステム監視およびアラートツールで、以下のような任意の数値時系列の記録に適合しています。

* メトリック名とキー/値のペアによる多次元時系列データ (Multi-dimensional time series data by metric name and key/value pairs)
* 分散型ストレージに依存しない (No reliance on distributed storage)
* HTTPを利用した時系列コレクション (Time series collection over HTTP)
* 中間ゲートウェイを介して時系列をプッシュすることができます (Pushing time series is supported via an intermediary gateway)
* サービスの発見または静的な設定 (Service discovery or static configuration)

==== 1. Create OpenShift Project

このステップでは、CoolStore アプリケーション用の新しい監視ツールを展開します。
そのため、monolith や以前に作成した他のマイクロサービスとは別のプロジェクトを作成しておきます。

{{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-coolstore-dev[Topology View^] に戻り、プロジェクトのドロップダウンをクリックして、Create Project を選択します。 

image::create_project.png[create_dialog, 700]

フィールドに以下の内容を入力し、 *Create* をクリックします。

* Name: `{{USER_ID}}-monitoring`
* Display Name: `{{USER_ID}} CoolStore App Monitoring Tools`
* Description: 空欄にする

image::create_monitoring_dialog.png[create_dialog, 700]

==== 2. Deploy Jaeger to OpenShift

新しいプロジェクトで `+Add` をクリックし、 *From Catalog* を選択します。

jaeger サーバーを導入するには、右上の `+` アイコンをクリックします。

image::plus-icon.png[serverless, 500]

以下の _Service_ を `YAML` エディタでコピーし、 *Create* をクリックします。

[source,yaml,role="copypaste"]
----
apiVersion: jaegertracing.io/v1
kind: Jaeger
metadata:
  name: jaeger-all-in-one-inmemory
  namespace: {{ USER_ID }}-monitoring
----

{{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-monitoring[Topology View^] では、Jaegerがデプロイされているのが確認できます。

image::jaeger_top.png[create_dialog, 500]

==== 4. Observe Jaeger UI

デプロイが完了したら（紺色の丸印！）、 https://jaeger-all-in-one-inmemory-{{USER_ID}}-monitoring.{{ ROUTE_SUBDOMAIN}}[Jaeger UI^] を開きます。

これは Jaeger の UI です。今のところ監視しているアプリがないので割と使い勝手が悪いように見えますが、心配しないしてください！
次のステップではトレースデータを活用していきます。

image::jaeger-ui.png[jaeger_ui, 700]

==== 5. Utilizing Opentracing with Inventory (Quarkus)

クラウドネイティブアプリケーションの一部として Quarkus で書かれたインベントリサービスを呼び出す、 Spring Boot で書かれたカタログサービスがあります。これらのアプリケーションは、 Jaeger を使って簡単にトレースすることができます。

このステップでは、 *smallrye-opentracing* を使用するためのインベントリアプリケーションに Quarkus の拡張機能を追加します。以下のコマンドを実行して、 CodeReady Workspaces Terminal 経由でトレース拡張機能を追加します。

[source,sh,role="copypaste"]
----
mvn quarkus:add-extension -Dextensions="smallrye-opentracing" -f $CHE_PROJECTS_ROOT/cloud-native-workshop-v2m2-labs/inventory
----

下記を見てください。

[source,console]
----
✅ Adding extension io.quarkus:quarkus-smallrye-opentracing
----

それから `BUILD SUCCESS`。
これにより、インベントリマイクロサービスのために拡張機能の依存関係が `pom.xml` に追加されることが保証されます。

[NOTE]
====
https://vertx.io/[Vert.x^] 、 http://camel.apache.org/[Apache Camel^] 、 http://infinispan.org/[Infinispan^] 、Spring DI互換性（ `@Autowired` など）など、人気のあるフレームワークの Quarkusの https://quarkus.io/extensions/[拡張機能^] は他にもたくさんあります。
====

==== 6. Create the configuration

このステップを始める前に、 {{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-monitoring[Topology View^] にアクセスして *jaeger-collector* サービスを確認し、_jaeger_ デプロイメントをクリックして _Resources_ タブを選択して、 Jaeger によって公開されているサービスを表示します。

image::jaeger-services.png[create_dialog, 700]

ポート `14268` で `http-c-binary-trft` サービスを使用してトレースを報告するようにアプリを設定します。

workspace `cloud-native-workshop-v2m2-lab` の下にある `inventory` プロジェクトで、 `src/main/resources/application.properties` ファイルを開き、 CodeReady Workspaces Terminal を通じて以下の設定を追加します。

[source,properties,role="copypaste"]
----
# Jaeger configuration
%prod.quarkus.jaeger.service-name=inventory
%prod.quarkus.jaeger.sampler-type=const
%prod.quarkus.jaeger.sampler-param=1
%prod.quarkus.jaeger.endpoint=http://jaeger-all-in-one-inmemory-collector.{{ USER_ID }}-monitoring.svc.cluster.local:14268/api/traces
----

環境変数やJVMのプロパティを使って設定を指定することもできます。 https://www.jaegertracing.io/docs/1.12/client-features/[Jaeger Features^] を参照してください。

[NOTE]
====
もし `quarkus.jaeger.service-name` プロパティ (または環境変数 `JAEGER_SERVICE_NAME`) が指定されていない場合は、`no-op` トレーサーが設定され、バックエンドにトレースデータが報告されません。
====

[NOTE]
====
アプリケーションには特定のトレースコードは含まれていません。デフォルトでは、アプリに送信された RESTful リクエストは、MicroProfile Tracing のおかげで *コードの変更を必要とせず* にトレースされます。また、トレース情報を強化し、他のメソッドやクラスを手動でトレースすることも可能です。これについての詳細は、 https://github.com/eclipse/microprofile-opentracing/blob/master/spec/src/main/asciidoc/microprofile-opentracing.asciidoc[MicroProfile OpenTracing specification^] 仕様を参照してください。
====

==== 7. Re-Deploy to OpenShift

ターミナルを介してインベントリアプリケーションをリパッケージし、再デプロイします。

[source,sh,role="copypaste"]
----
oc project {{ USER_ID }}-inventory && \
mvn package -DskipTests -f $CHE_PROJECTS_ROOT/cloud-native-workshop-v2m2-labs/inventory
----

コンソールと {{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-inventory[Inventory Topology View^] で、再構築と再展開が完了するのを待ちます。

==== 8. Observing Jaeger Tracing

ネットワークとデータトランザクションをトレースするために、 CodeReady Workspaces Terminal を介して *curl* コマンドを使用してInventoryサービスを呼び出します。

トレースを生成するには、インベントリを10回呼び出します。

[source,sh,role="copypaste"]
----
URL="http://$(oc get route -n {{ USER_ID }}-inventory inventory -o jsonpath={% raw %}"{.spec.host}"{% endraw %})"

for i in $(seq 1 10) ; do
  curl -s $URL/services/inventory/165613
  sleep .2
done
----

http://jaeger-query-{{USER_ID}}-monitoring.{{ ROUTE_SUBDOMAIN}}[Jaeger UI^] をリロードすると、新しい `inventory` サービスが Jaeger 自身のサービスと並んで表示されることに気づくでしょう。

image::jaeger-2-services.png[jaeger_ui, 700]

`inventory` サービスを選択し、 *Find Traces* をクリックして、グラフ上の最初のトレースを観察します。

image::jaeger-reload.png[jaeger_ui, 700]

単一の *Span* をクリックすると、操作名、操作の開始時刻、期間を持つ論理的な作業単位が Jaeger に表示されます。 Span は、因果関係をモデル化するために入れ子にしたり、順序をつけたりすることができます。

image::jaeger-span.png[jaeger_ui, 700]

アプリケーションがより複雑になり、多くのマイクロサービスが互いに呼び合うようになると、これらの Span やトレースはより複雑になりますが、アプリの問題点も明らかになります。

==== 9. Deploy Prometheus and Grafana to OpenShift

OpenShift Container Platformは、 https://prometheus.io[Prometheus] オープンソースプロジェクトとその広範なエコシステムをベースにした、構成済みで自己更新型の監視スタックを搭載して提供されます。クラスタコンポーネントの監視を提供し、発生した問題をクラスタ管理者に即座に通知する一連のアラートと一連の https://grafana.com/[Grafana] ダッシュボードを搭載しています。

image::monitoring-diagram.png[Prometheus, 700]

ただし、インベントリとカタログアプリケーションのサービスメトリクスをスクレイプするために、カスタムの *Prometheus* をデプロイします。そして、そのメトリクスデータを *Grafana* ダッシュボードを使って可視化していきます。

{{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-monitoring[Monitoring Topology View^] で、 `+Add` をクリックし、 *Container Image* を選択します。

image::add-to-project.png[Prometheus, 800]

以下の項目を記入してください。

* *Image Name*: `prom/prometheus:latest`
* *Application Name*: `prometheus-app`
* *Name*: `prometheus`

*Enter* を押すと、30秒後に *緑色のチェック付き* アイコンと *Validated* が表示されます。

残りはそのままにして、 *Create* をクリックします。

image::search-prometheus-image.png[Prometheus, 700]

Topology view では、 prometheus が回転しているのがわかります。それが完了したら、矢印をクリックして prometheus query UI にアクセスします。

image::prometheus-route.png[Prometheus, 700]

これは Prometheus Web UI をロードするはずです（これは後で使います）。

image::prometheus-webui.png[Prometheus, 700]

==== Deploy Grafana

先ほどと同じ手順で行います。 {{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-monitoring[Monitoring Topology View^] で、 `+Add` をクリックして、 *Container Image* ,を選択し、フィールドに記入します。

* *Image Name*: `grafana/grafana:latest`
* *Application*: `grafana-app`
* *Name*: `grafana`

image名の横にある "虫眼鏡" の検索アイコンをクリックして、image が存在することを確認してください。

*Enter* を押すと、30秒後に *緑色のチェック付き* アイコンと *Validated* が表示されます。

残りはそのままにして、 *Create* をクリックします。

image::search-grafana-image.png[Grafana, 700]

Topology view では、 Grafana が回転しているのがわかります。それが完了したら、矢印をクリックして Grafana UI にアクセスします。

image::grafana-route.png[Prometheus, 700]

これは Grafana Web UI をロードする必要があります。

image::grafana-login.png[Grafana, 700]

以下の値を使用して Grafana Web UI にログインします。

* Username: `admin`
* Password: `admin`

新しいパスワードを *スキップ* して下さい。(または覚えている他のものに変更)

このように Grafana のランディングページが表示されます。

image::grafana-webui.png[Grafana, 700]

==== 10. Add a data source to Grafana

Add data source をクリックし、データソースのタイプとして *Prometheus* を選択します。

image::grafana-datasource-types.png[Grafana, 700]

以下の値を記入してください。

* *URL*: `http://prometheus.{{USER_ID}}-monitoring:9090`

*Save & Test* をクリックして、成功のメッセージが表示されたことを確認します。

image::grafana-ds-success.png[Grafana, 300]

この時点で、 Granana は、監視しているアプリケーションから収集したメトリクスを Prometheus から引き出すように設定されています。

==== 11. Utilize metrics specification for Inventory Microservice

このステップでは、 _Inventory(Quarkus)_ アプリケーションが *SmallRye Metrics extension* を通じて MicroProfile Metrics 仕様を利用する方法を学びます。 _MicroProfile Metrics_ を使用すると、アプリケーション内で何が起こっているかについての洞察を提供する様々なメトリクスや統計情報を収集することができます。

メトリクスは、JSON 形式または *OpenMetrics* 形式を使用してリモートで読み込むことができます。
_Prometheus_のような追加ツールで処理し、分析や可視化のために保存することができるようにします。

CodeReady ターミナルで以下のコマンドを使用して、 _smallrye-metrics_ を使用するために必要な Quarkus の拡張機能を Inventory アプリケーションに追加します。

[source,sh,role="copypaste"]
----
mvn quarkus:add-extension -Dextensions="metrics" -f $CHE_PROJECTS_ROOT/cloud-native-workshop-v2m2-labs/inventory
----

出力を確認してみてください。

[source,console]
----
✅ Adding extension io.quarkus:quarkus-smallrye-metrics
----

目的のメトリクスが時間の経過とともに計算され、 _Prometheus_ や _Grafana_ で処理するためにエクスポートできるように、いくつかのアノテーションを追加してみましょう。

集めようとしているメトリクスは、以下のようなものです。

* *performedChecksAll*: _getAll()_ が何回実行されたかを表すカウンタ。
* *checksTimerAll*: _getAll()_ メソッドを実行するのにかかる時間の目安。
* *performedChecksAvail*: _getAvailability()_ が何回呼ばれたかを表すカウンタ
* *checksTimerAvail*: _getAvailability()_ メソッドを実行するのにかかる時間の目安。

_cloud-native-workshop-v2m2-labs/inventory_ プロジェクトで、 `src/main/java/com/redhat/coolstore/InventoryResource.java` を開きます。
2 つのメソッド _getAll()_ と _getAvailability()_ を、カスタム・メトリクス ( *@Counted* , *@Timed* ) のためのいくつかのアノテーションを追加した以下のコードで置き換えます。

[source,java,role="copypaste"]
----
    @GET
    @Counted(name = "performedChecksAll", description = "How many getAll() have been performed.")
    @Timed(name = "checksTimerAll", description = "A measure of how long it takes to perform the getAll().", unit = MetricUnits.MILLISECONDS)
    public List<Inventory> getAll() {
        return Inventory.listAll();
    }

    @GET
    @Counted(name = "performedChecksAvail", description = "How many getAvailability() have been performed.")
    @Timed(name = "checksTimerAvail", description = "A measure of how long it takes to perform the getAvailability().", unit = MetricUnits.MILLISECONDS)
    @Path("{itemId}")
    public List<Inventory> getAvailability(@PathParam String itemId) {
        return Inventory.<Inventory>streamAll()
        .filter(p -> p.itemId.equals(itemId))
        .collect(Collectors.toList());
    }
----

上部に必要なインポートを追加します。

[source,java,role="copypaste"]
----
import org.eclipse.microprofile.metrics.MetricUnits;
import org.eclipse.microprofile.metrics.annotation.Counted;
import org.eclipse.microprofile.metrics.annotation.Timed;
----

==== 12. Redeploy to OpenShift

インベントリアプリケーションをリパッケージして再配置します。

[source,sh,role="copypaste"]
----
oc project {{ USER_ID }}-inventory && \
mvn clean package -DskipTests -f $CHE_PROJECTS_ROOT/cloud-native-workshop-v2m2-labs/inventory
----

`BUILD SUCCESS` を取得して、アプリが再デプロイされるはずです。
アプリが再デプロイされるまで {{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-inventory[Inventory Topology View^] を監視してください。

これが完了すると、ターミナルでこのコマンドを使用して、アプリによって公開されている生のメトリクスを見ることができるはずです。

[source,sh,role="copypaste"]
----
curl http://inventory-{{USER_ID}}-inventory.{{ ROUTE_SUBDOMAIN }}/metrics
----

OpenMetrics形式のメトリクスの束が表示されます。

[source,console]
----
# HELP vendor_memoryPool_usage_bytes Current usage of the memory pool denoted by the 'name' tag
# TYPE vendor_memoryPool_usage_bytes gauge
vendor_memoryPool_usage_bytes{name="PS Survivor Space"} 916920.0
# HELP vendor_memoryPool_usage_bytes Current usage of the memory pool denoted by the 'name' tag
# TYPE vendor_memoryPool_usage_bytes gauge
vendor_memoryPool_usage_bytes{name="PS Old Gen"} 1.489556E7
# HELP vendor_memory_maxNonHeap_bytes Displays the maximum amount of used non-heap memory in bytes.
# TYPE vendor_memory_maxNonHeap_bytes gauge
vendor_memory_maxNonHeap_bytes 4.52984832E8
# HELP vendor_memory_usedNonHeap_bytes Displays the amount of used non-heap memory in bytes.
# TYPE vendor_memory_usedNonHeap_bytes gauge
vendor_memory_usedNonHeap_bytes 5.4685184E7
... and more
----

これは、クラスタにデプロイしたときに、プロメテウスがアプリのメトリクスにアクセスしてインデックスを作成するために使用するものです。しかし、最初に Prometheus にこのことを伝えなければなりません。

==== Configure Prometheus ConfigMap

Prometheus にアプリからメトリクスをスクレイプするように指示するには、Kubernetes _ConfigMap_ を作成する必要があります。

{{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-monitoring[Monitoring Topology View^] 上で、左の `+Add` をクリックし、今回は *YAML* を選択します。

image::add-yaml.png[prometheus, 700]

空のボックスに、以下のYAMLコードを貼り付けます。

[source,yaml,role="copypaste"]
----
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: {{USER_ID}}-monitoring
data:
  prometheus.yml: >-
    scrape_configs:
      - job_name: 'prometheus'
        static_configs:
        - targets: ['localhost:9090']

      - job_name: 'inventory-quarkus'
        scrape_interval: 10s
        scrape_timeout: 5s
        static_configs:
        - targets: ['inventory.{{USER_ID}}-inventory.svc.cluster.local:8080']
----

*Create* をクリックして下さい。

Config maps はキーと値のペアを保持しており、上記のコマンドでは *prometheus-config* という Config maps が *prometheus.yml* をキー、上記の内容を値として作成されています。コンフィグマップがコンテナに注入されるたびに、ファイルシステム上の指定されたパスに、キーと同じ名前のファイルとして表示されます。

次に、Prometheus コンテナが読めるように、この Config Map をファイルシステムに _マウント_ する必要があります。このコマンドを実行して、Prometheus デプロイメントをマウントするように変更します。

[source,sh,role="copypaste"]
----
oc set volume -n {{USER_ID}}-monitoring deployment/prometheus --add -t configmap --configmap-name=prometheus-config -m /etc/prometheus/prometheus.yml --sub-path=prometheus.yml && \
oc rollout status -n {{USER_ID}}-monitoring -w deployment/prometheus
----

これは prometheus の新しいデプロイメントを指示します。完了までお待ちください!

==== 13. Generate some values for the metrics

Prometheus がアプリから値を取得しているので、インベントリサービスを複数回呼び出すループを書いて、メトリクスを観察してみましょう。次のコマンドを使用します。

[source,sh,role="copypaste"]
----
URL=http://$(oc get route -n {{ USER_ID }}-inventory inventory -o jsonpath={% raw %}"{.spec.host}"{% endraw %})

for i in $(seq 1 600) ; do
  curl -s $URL/services/inventory/165613
  curl -s $URL/services/inventory
  sleep 1
done
----
このループを実行したままにしておきます（600秒後、または10分後に終了します）。

メトリクスを見る方法は3つあります。

. `curl` commands (which you already did)
. Prometheus Queries
. Grafana Dashboards

==== Using Prometheus

http://prometheus-{{USER_ID}}-monitoring.{{ ROUTE_SUBDOMAIN }}[Prometheus UI^] を開き、 `performedChecks` と入力して自動補完の値を選択します。

image::prometheus-metrics-console.png[metrics_prometheus, 900]

*Graph* タブに切り替えます。

image::prometheus-metrics-graph.png[metrics_prometheus, 900]

このメトリックのために、時間の値で遊んだり、異なる時間範囲で異なるデータを見たりすることができます。
他にも多くのメトリクスがあり、 https://prometheus.io/docs/prometheus/latest/querying/basics/[Prom QL^] (Prometheus Query Language) を使用してクエリを実行したり、非常に複雑なクエリを実行したりすることができます。

==== Using Grafana

http://grafana-{{USER_ID}}-monitoring.{{ ROUTE_SUBDOMAIN }}[Grafana UI^] を開きます。

*New Dashboard* を選択して、メトリクスを確認するための新しい _Dashboard_ を作成します。

image::grafana-create-dashboard.png[metrics_grafana, 900]

*Add new panel* をクリックすると、クエリで新しいパネルが追加されます。

image::grafana-add-query.png[metrics_grafana, 700]

_Metrics_フィールドに `performedChecks` と入力し、最初に自動補完された値を選択します。

image::grafana-add-query-detail.png[metrics_grafana, 700]

カーソルがフィールドに入っている間に kbd:[ENTER] を押すと、値が表示されます。表示されているようにドロップダウンから *Last 15 Minutes* を選択します。

image::grafana-add-query-detail2.png[metrics_grafana, 700]

グラフの種類（棒グラフ、線グラフ、ゲージなど）とともに、表示を微調整することができます。終わったら、*Save* ボタンをクリックして、新しいダッシュボードに名前を付けて、*Save* をクリックします。

image::grafana-add-query-detail3.png[metrics_grafana, 700]

これはオプションですが、必要に応じて Panel を追加することもできます。JVM RSSの値 `process_resident_memory_bytes` (Visualizationの `Gauge` と _Field_ タブの単位を `bytes(IEC)` に、 _Panel Title_ のタイトルを `Memory` に設定します)。こんな感じになるかもしれません。

image::grafana-add-query-detail4.png[metrics_grafana, 700]

https://grafana.com/grafana/dashboards[Grafana Labs Dashboard community^] から、より複雑なダッシュボードの例を見ることができ、さらには自分のダッシュボードにインポートすることもできます。

=== Extra Credit: Spring Boot

Spring Boot は Prometheus が収集したメトリクスを公開し、Grafana で表示することもできます。Spring Boot で書かれたカタログサービスにメトリクスのサポートを追加するには、以下のようにする必要があります。

. Spring Boot Actuator と Prometheus の依存関係を追加します
.  `application-openshift.properties` を config 値で設定します。
. 以前のモジュールのコマンドを使用して、アプリを再構築し、OpenShiftに再デプロイします。（ {{USER_ID}}-catalog project 内）
. Prometheus _ConfigMap_ を編集して、 `catalog-springboot.{{USER_ID}}-catalog.svc.cluster.local:8080` を指す別のスクレイプジョブを追加します。
. Prometheus を再デプロイして新しい config を取得します。
. Prometheus に Spring Boot のメトリクス(scrape_duration_secondsなど)を問い合わせてみます。

このラボの範疇を超えていますが、興味のある方、時間に余裕のある方は、是非やってみてください。

=== Summary

このラボでは、 Jaeger、Prometheus、Grafana を使用してクラウドネイティブアプリケーションを監視する方法を学びました。また、 Quarkus を使用することで、開発者やオペレータとしての観察タスクが容易になることも学びました。これらのテクニックを将来のプロジェクトで使用して、分散型クラウドネイティブアプリケーションを監視することができます。
